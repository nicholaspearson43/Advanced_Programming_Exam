{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmdTDCZJscwIhpTlCmXmk3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicholaspearson43/Advanced_Programming_Exam/blob/main/Deep%20Learning%20HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning AY 2021/22\n",
        "## First compulsory assignment - Nicholas Pearson - SM3500457\n"
      ],
      "metadata": {
        "id": "49KudK4tfC3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1\n",
        "Build the Multilayer Perceptron (MLP) represented in the last image of the notebook using PT built-ins, with the assumptions written just below the image (\"We suppose that...\")\n",
        "## A1"
      ],
      "metadata": {
        "id": "rDAjpIiQfWxn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pluzFjolqxox"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1=torch.nn.Linear(in_features=5, out_features=11, bias=False)\n",
        "    self.layer2=torch.nn.Linear(in_features=11, out_features=16, bias=False)\n",
        "    self.layer3=torch.nn.Linear(in_features=16, out_features=13, bias=False)\n",
        "    self.layer4=torch.nn.Linear(in_features=13, out_features=8, bias=False)\n",
        "    self.layer5=torch.nn.Linear(in_features=8, out_features=4, bias=False)\n",
        "\n",
        "  def forward(self, X):\n",
        "    out = self.layer1(X)\n",
        "    out = torch.nn.functional.relu(out)\n",
        "    out = self.layer2(out)\n",
        "    out = torch.nn.functional.relu(out)\n",
        "    out = self.layer3(out)\n",
        "    out = torch.nn.functional.relu(out)\n",
        "    out = self.layer4(out)\n",
        "    out = torch.nn.functional.relu(out)\n",
        "    out = self.layer5(out)\n",
        "    out = torch.nn.functional.softmax(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "IPtIi9xZq4wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2\n",
        "Provide calculation for the exact number of parameters of this MLP.\n",
        "Do it first supposing that the layers don't have a bias term, then supposing that the bias is present wherever it's possible\n",
        "\n",
        "##A2\n",
        "No bias:\n",
        "$(5 \\cdot 11)+(11 \\cdot 16)+(16\\cdot13)+(13\\cdot8)+(8\\cdot4)=575$\n",
        "\n",
        "With bias:\n",
        "$(5 \\cdot 11+11)+(11 \\cdot 16+16)+(16\\cdot13+13)+(13\\cdot8+8)+(8\\cdot4+4)=627$"
      ],
      "metadata": {
        "id": "n6is31xJgCAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3\n",
        "Calculate the L1 (vectorial) norm and the Frobenius norm for the params of each layer\n",
        "## A3\n",
        "\n"
      ],
      "metadata": {
        "id": "8IBveHDeg3T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP()"
      ],
      "metadata": {
        "id": "yEItmwhetiOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  print(\"L1 Norm:\", torch.norm(param, 1).item())\n",
        "  print(\"Frobenius Norm:\", torch.norm(param, p='fro').item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKEtP5wNhI2C",
        "outputId": "bed76b84-6ef9-4ddd-b3a7-07dc0d342e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Norm: 11.597103118896484\n",
            "Frobenius Norm: 1.814905047416687\n",
            "L1 Norm: 26.469280242919922\n",
            "Frobenius Norm: 2.317514181137085\n",
            "L1 Norm: 27.99208641052246\n",
            "Frobenius Norm: 2.2081501483917236\n",
            "L1 Norm: 14.560702323913574\n",
            "Frobenius Norm: 1.6691266298294067\n",
            "L1 Norm: 5.559162139892578\n",
            "Frobenius Norm: 1.134905219078064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4\n",
        "Given 10 random datapoints, feed them into the network. This operation must be done all in one single command and must not make use of loops.\n",
        "- Given the output of the network, using PyTorch code, find the class of assignment of each datapoint. This also must be done in a single PyTorch command without using loops.\n",
        "- Drafting a vector of ground truths (whichever labels you like), provide code for the calculation of the accuracy\n",
        "    - Tip: first get the number of correct assignments, then...\n",
        "\n",
        "## A4"
      ],
      "metadata": {
        "id": "k24Shl-ahzCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model(torch.rand((10,5)))\n",
        "print(y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTaOnsnxiC18",
        "outputId": "8e26547a-052d-4e58-cff6-eec6d70ce42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2491, 0.2505, 0.2507, 0.2497],\n",
            "        [0.2498, 0.2502, 0.2501, 0.2499],\n",
            "        [0.2471, 0.2508, 0.2533, 0.2487],\n",
            "        [0.2495, 0.2504, 0.2506, 0.2496],\n",
            "        [0.2485, 0.2503, 0.2513, 0.2499],\n",
            "        [0.2484, 0.2505, 0.2514, 0.2497],\n",
            "        [0.2486, 0.2503, 0.2517, 0.2494],\n",
            "        [0.2490, 0.2506, 0.2517, 0.2487],\n",
            "        [0.2493, 0.2502, 0.2507, 0.2498],\n",
            "        [0.2491, 0.2504, 0.2509, 0.2496]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_class = torch.max(y_hat, dim=1).indices\n",
        "print(y_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPV8wlQWiNFF",
        "outputId": "d159adf1-5de2-4215-b0a3-7e8346ae6fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 1, 2, 2, 2, 2, 2, 2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = torch.randint(0,4,(10,))\n",
        "print(y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4FY-R5Rif9Q",
        "outputId": "7ef49074-de9b-449d-f4ee-12d4b6ae3f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 0, 0, 2, 1, 2, 3, 0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = torch.mean((y_true==y_class).float())\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3KTQAP3ivQP",
        "outputId": "3ac2c70c-b04f-4906-a0a5-0f5dc1caa9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3000)\n"
          ]
        }
      ]
    }
  ]
}